# ðŸš€ Crypto ETL Pipeline + ML Predictor

Pipeline ETL automatizado que extrae datos de criptomonedas desde CoinGecko API, los procesa, almacena en BigQuery, genera features temporales para Machine Learning y entrena modelos para predecir movimientos de precios.

---

## ðŸ“– DescripciÃ³n

Sistema completo de **ETL + Machine Learning** para anÃ¡lisis y predicciÃ³n de precios de criptomonedas:

- **ETL Pipeline:** Extrae, transforma y carga datos cada 6 horas (GitHub Actions)
- **AcumulaciÃ³n HistÃ³rica:** Almacena datos con UPSERT logic para evitar duplicados
- **Feature Engineering Temporal:** Genera 86+ features (lags, rolling stats, RSI, momentum)
- **ML Predictor:** Modelo Random Forest que predice direcciÃ³n de precio (UP/DOWN)
- **Test-Driven Development:** 62 tests automatizados (100% pasando)

---

## ðŸŽ¯ Objetivos

1. âœ… **Automatizar** la extracciÃ³n de datos de criptomonedas
2. âœ… **Acumular historial** para anÃ¡lisis temporal robusto
3. âœ… **Generar features ML** avanzadas (lags, rolling windows, RSI)
4. âœ… **Entrenar modelos** de predicciÃ³n de precios
5. âœ… **Hacer predicciones** en tiempo real
6. âœ… **Monitorear** calidad y cobertura de datos

---

## ðŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CoinGecko API  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ extract.py (cada 6h)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   data/raw/     â”‚ JSON
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ transform.py
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚data/processed/  â”‚ Parquet
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ load_historical.py (UPSERT)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       BigQuery (GCP)              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ prices_historical            â”‚ â”‚ â† Datos raw acumulados
â”‚ â”‚ (partitioned by date)        â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚              â”‚                    â”‚
â”‚              â”‚ feature_engineering_temporal.py
â”‚              â–¼                    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ prices_ml_features           â”‚ â”‚ â† 86+ features ML
â”‚ â”‚ (lag, rolling, RSI, momentum)â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ ml/train_bitcoin_predictor.py
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  models/*.pkl   â”‚ â† Modelos entrenados
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ ml/predictor.py
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PREDICCIÃ“N     â”‚ UP/DOWN + Confianza
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“‚ Estructura del Proyecto

```
    crypto-etl-pipeline/
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ automated_etl_pipeline.yml    # Ejecuta ETL cada 6 horas
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # JSON de CoinGecko (gitignored)
â”‚   â””â”€â”€ processed/                    # Parquet transformados (gitignored)
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ data_loader.py                # Carga datos de BigQuery
â”‚   â”œâ”€â”€ feature_engineer.py           # Prepara features ML
â”‚   â”œâ”€â”€ model_trainer.py              # Entrena Random Forest
â”‚   â”œâ”€â”€ model_evaluator.py            # EvalÃºa mÃ©tricas
â”‚   â”œâ”€â”€ predictor.py                  # Hace predicciones
â”‚   â””â”€â”€ train_bitcoin_predictor.py    # Script de entrenamiento
â”œâ”€â”€ models/
â”‚   â””â”€â”€ bitcoin_predictor_*.pkl       # Modelos entrenados (gitignored)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract.py                    # Extrae de CoinGecko API
â”‚   â”œâ”€â”€ transform.py                  # Transforma con Pandas
â”‚   â”œâ”€â”€ load_historical.py            # Carga a BigQuery (UPSERT)
â”‚   â”œâ”€â”€ feature_engineering_temporal.py  # Genera features ML
â”‚   â””â”€â”€ monitoring_dashboard.py       # Monitoreo de datos
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ test_ml_*.py                  # 27 tests ML
â”‚   â”œâ”€â”€ test_upsert_load.py           # 10 tests UPSERT
â”‚   â”œâ”€â”€ test_feature_engineering_temporal.py  # 13 tests
â”‚   â””â”€â”€ test_data_integrity.py        # 12 tests integridad
â”œâ”€â”€ Arquitecture.md                   # Reglas de desarrollo (TDD)
â”œâ”€â”€ ML_USAGE.md                       # DocumentaciÃ³n ML completa
â”œâ”€â”€ README.md                         # Este archivo
â””â”€â”€ requirements.txt                  # Dependencias Python
```

---

## ðŸš€ Inicio RÃ¡pido

### 1. Clonar repositorio

```bash
git clone https://github.com/Alejandro-Raposo/crypto-etl-pipeline.git
cd crypto-etl-pipeline
```

### 2. Crear entorno virtual

```bash
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar credenciales

Crear archivo `.env` en la raÃ­z:

```env
ETL_SERVICE_ACOUNT_CREDENTIALS_ROUTE=path/to/gcp_credentials.json
```

### 5. Ejecutar pipeline ETL (manual)

```bash
# Extraer
python scripts/extract.py

# Transformar
python scripts/transform.py

# Cargar
python scripts/load_historical.py

# Features ML
python scripts/feature_engineering_temporal.py
```

### 6. Entrenar modelo ML

```bash
python ml/train_bitcoin_predictor.py
```

### 7. Hacer predicciÃ³n

```bash
python ml/predictor.py
```

**Salida:**
```
============================================================
PREDICCIÃ“N COMPLETADA
============================================================

DirecciÃ³n: UP â†—ï¸
Confianza: 57.78%

PredicciÃ³n: El precio SUBE (Confianza: 57.8%)
============================================================
```

---

## ðŸ¤– Sistema de Machine Learning

### Objetivo

Predecir si el precio de **Bitcoin subirÃ¡ o bajarÃ¡** en la prÃ³xima hora.

### Modelo

- **Tipo:** ClasificaciÃ³n binaria (UP=1, DOWN=0)
- **Algoritmo:** Random Forest (100 Ã¡rboles)
- **Features:** 12 (lags, medias mÃ³viles, RSI, volatilidad, momentum)
- **NormalizaciÃ³n:** MinMaxScaler (0-1)

### MÃ©tricas Actuales

```
Accuracy:  66.67%
Precision: 66.67%
Recall:    100.00%
F1-Score:  80.00%
```

âš ï¸ **Nota:** Modelo entrenado con 13 registros. MejorarÃ¡ con mÃ¡s datos histÃ³ricos.

### DocumentaciÃ³n Completa

Ver **[ML_USAGE.md](ML_USAGE.md)** para:
- Uso programÃ¡tico (Python)
- InterpretaciÃ³n de resultados
- Workflow recomendado
- 27 tests implementados

---

## âš™ï¸ AutomatizaciÃ³n (GitHub Actions)

El pipeline se ejecuta **automÃ¡ticamente cada 6 horas**:

1. âœ… Extrae datos de CoinGecko API
2. âœ… Transforma y limpia
3. âœ… Carga a BigQuery con UPSERT
4. âœ… Genera features ML temporales

### Configurar GitHub Actions

1. Crear secret `GCP_SERVICE_ACCOUNT_KEY` en GitHub:
   - Settings â†’ Secrets and variables â†’ Actions â†’ New secret
   - Pegar el contenido completo del JSON de credenciales GCP

2. El workflow se ejecuta automÃ¡ticamente (cron: `0 */6 * * *`)

3. TambiÃ©n se puede ejecutar manualmente:
   - Actions â†’ Automated ETL Pipeline â†’ Run workflow

---

## ðŸ“Š Monitoreo

### Ver cobertura de datos

```bash
python scripts/monitoring_dashboard.py
```

**Salida:**
```
========================================
DASHBOARD: COBERTURA TEMPORAL DE DATOS
========================================

Total registros: 13
Cryptos Ãºnicas: 1 (Bitcoin)
Fechas Ãºnicas: 13
Horas cubiertas: ~13 horas

Registro mÃ¡s antiguo: 2025-10-01 12:00:00
Registro mÃ¡s reciente: 2025-10-06 18:00:00

Completeness Score: 85.0%
```

---

## ðŸ§ª Tests (62 tests - 100% pasando)

### Ejecutar todos los tests

```bash
pytest test/ -v
```

### Tests por mÃ³dulo

```bash
# Tests ML (27 tests)
pytest test/test_ml_*.py -v

# Tests ETL (35 tests)
pytest test/test_upsert_load.py -v
pytest test/test_feature_engineering_temporal.py -v
pytest test/test_data_integrity.py -v
```

### Cobertura

- âœ… **ETL:** UPSERT logic, feature engineering, integridad temporal
- âœ… **ML:** Data loader, feature engineer, trainer, evaluator, predictor
- âœ… **BigQuery:** Queries, schema, partitioning

---

## ðŸ“ˆ Datasets en BigQuery

### `crypto_dataset.prices_historical`

Tabla particionada por fecha con datos raw acumulados:

- `id`, `symbol`, `name`
- `current_price`, `market_cap`, `volume_24h`
- `last_updated`, `partition_date`
- `composite_key` (deduplicaciÃ³n)

### `crypto_dataset.prices_ml_features`

Tabla con 86+ features para ML:

- Lags: 1h, 3h, 6h, 12h, 24h, 48h, 7d
- Rolling stats: mean, std, min, max (6h, 12h, 24h, 48h, 168h)
- RSI: 14h, 24h
- Momentum, volatilidad, cambios porcentuales
- Features cÃ­clicas: hora, dÃ­a de la semana (sin/cos)

---

## ðŸ”§ TecnologÃ­as Utilizadas

| CategorÃ­a | TecnologÃ­a |
|-----------|-----------|
| **Lenguaje** | Python 3.13 |
| **ETL** | Pandas, Requests, Pyarrow |
| **Cloud** | Google Cloud BigQuery |
| **ML** | scikit-learn (Random Forest) |
| **AutomatizaciÃ³n** | GitHub Actions |
| **Testing** | pytest |
| **GestiÃ³n deps** | pip, venv |

---

## ðŸ“‹ Dependencias (requirements.txt)

```
requests>=2.32.0
pandas>=2.3.0
pyarrow>=21.0.0
google-cloud-bigquery>=3.38.0
pandas-gbq>=0.29.0
db-dtypes>=1.4.0
sqlalchemy>=2.0.0
python-dateutil>=2.9.0
python-dotenv>=1.1.0
numpy>=2.3.0
scikit-learn>=1.5.0
```

---

## ðŸ“– Reglas de Desarrollo

Ver **[Arquitecture.md](Arquitecture.md)** para:

- âœ… **TDD estricto** (tests ANTES del cÃ³digo)
- âœ… CÃ³digo limpio y organizado
- âœ… Rendimiento Ã³ptimo
- âœ… Sin cÃ³digo duplicado (DRY)
- âœ… Funciones cortas (<50 lÃ­neas)

**Regla #7 (TDD)** es la mÃ¡s crÃ­tica: los tests se diseÃ±an ANTES de implementar funcionalidad.

---

## ðŸŽ¯ Roadmap

### Completado âœ…

- [x] ETL Pipeline automatizado
- [x] AcumulaciÃ³n histÃ³rica con UPSERT
- [x] Feature Engineering temporal (86+ features)
- [x] Modelo ML Random Forest
- [x] Sistema de predicciÃ³n en tiempo real
- [x] 62 tests automatizados
- [x] Monitoreo de cobertura de datos
- [x] GitHub Actions (cada 6 horas)

### PrÃ³ximos Pasos ðŸ”²

- [ ] Esperar acumulaciÃ³n de datos (2-3 semanas)
- [ ] Reentrenar modelo con mÃ¡s snapshots
- [ ] Probar con otras cryptos (Ethereum, Solana)
- [ ] Implementar cross-validation
- [ ] Dashboard web interactivo (Streamlit/Dash)
- [ ] API REST para predicciones
- [ ] Probar LSTM para secuencias temporales
- [ ] Ensemble de modelos

---

## âš ï¸ Advertencias

Este sistema es **educativo/experimental**:

- âš ï¸ NO usar para decisiones financieras reales
- âš ï¸ El mercado cripto es altamente volÃ¡til
- âš ï¸ Resultados pasados NO garantizan resultados futuros
- âš ï¸ Modelo actual tiene datos limitados (13 registros)

---

## ðŸ‘¨â€ðŸ’» Autor

**Alejandro Raposo**

- GitHub: [@Alejandro-Raposo](https://github.com/Alejandro-Raposo)
- Repositorio: [crypto-etl-pipeline](https://github.com/Alejandro-Raposo/crypto-etl-pipeline)

---

## ðŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo licencia MIT.

---

## ðŸŽ“ Aprendizajes Clave

Este proyecto demuestra:

1. âœ… **ETL end-to-end** con automatizaciÃ³n
2. âœ… **Cloud integration** (GCP BigQuery)
3. âœ… **Machine Learning** aplicado a finanzas
4. âœ… **Test-Driven Development** estricto
5. âœ… **CI/CD** con GitHub Actions
6. âœ… **CÃ³digo profesional** y escalable
7. âœ… **Monitoreo** y validaciÃ³n de datos

---

**Sistema ETL + ML completo y profesional** ðŸš€âœ¨

Para mÃ¡s informaciÃ³n sobre el sistema ML, ver **[ML_USAGE.md](ML_USAGE.md)**
